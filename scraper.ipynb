{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBA DX project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, Comment\n",
    "import pathlib\n",
    "import json\n",
    "import time\n",
    "from scraper.scraper import scrap_functions\n",
    "from scraper.scraper import get_player_seasons\n",
    "from scraper.url import get_seasons_url, get_players_url, get_player_soup\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from const import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download HTML to scrape\n",
    "seasons = get_seasons_url(START_YEAR, END_YEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "# loop through the seasons\n",
    "for season in seasons:\n",
    "    player_urls = get_players_url(season)\n",
    "\n",
    "    # add new player_urls to urls\n",
    "    urls.extend(player_urls)\n",
    "\n",
    "urls = list(set(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2017-18', '2016-17', '2015-16', '2019-20', '2018-19', '2020-21']\n",
      "2017-18\n",
      "2016-17\n",
      "2015-16\n",
      "2019-20\n",
      "2018-19\n",
      "['2007-08', '2016-17', '2017-18', '2004-05', '2015-16', '2008-09', '2014-15', '2010-11', '2012-13', '2011-12', '2013-14', '2002-03', '2003-04', '2006-07', '2009-10', '2005-06']\n",
      "2016-17\n",
      "2017-18\n",
      "2015-16\n",
      "2014-15\n",
      "2010-11\n",
      "2012-13\n",
      "2011-12\n",
      "2013-14\n",
      "2009-10\n",
      "['2007-08', '2008-09', '2010-11', '2012-13', '2011-12', '2006-07', '2009-10', '2005-06']\n",
      "2010-11\n",
      "2012-13\n",
      "2011-12\n",
      "2009-10\n",
      "['2007-08', '2016-17', '2004-05', '2015-16', '2008-09', '2014-15', '2010-11', '2012-13', '2011-12', '2013-14', '2003-04', '2006-07', '2009-10', '2005-06']\n",
      "2016-17\n",
      "2015-16\n",
      "2014-15\n",
      "2010-11\n",
      "2012-13\n",
      "2011-12\n",
      "2013-14\n",
      "2009-10\n",
      "['2008-09', '2010-11', '2013-14', '2012-13', '2011-12', '2009-10']\n",
      "2010-11\n",
      "2013-14\n",
      "2012-13\n",
      "2011-12\n",
      "2009-10\n",
      "['2019-20', '2022-23', '2018-19', '2020-21', '2021-22']\n",
      "2019-20\n",
      "2018-19\n",
      "['2017-18', '2016-17', '2007-08', '2015-16', '2008-09', '2014-15', '2019-20', '2013-14', '2012-13', '2011-12', '2018-19', '2006-07', '2009-10']\n",
      "2017-18\n",
      "2016-17\n",
      "2015-16\n",
      "2014-15\n",
      "2019-20\n",
      "2013-14\n",
      "2012-13\n",
      "2011-12\n",
      "2018-19\n",
      "2009-10\n",
      "['2007-08', '2004-05', '2010-11', '2013-14', '2003-04', '2006-07', '2005-06']\n",
      "2010-11\n",
      "2013-14\n",
      "['2017-18', '2016-17', '2015-16', '2014-15', '2019-20', '2012-13', '2013-14', '2018-19', '2020-21']\n",
      "2017-18\n",
      "2016-17\n",
      "2015-16\n",
      "2014-15\n",
      "2019-20\n",
      "2012-13\n",
      "2013-14\n",
      "2018-19\n",
      "['2016-17', '2015-16', '2014-15', '2019-20', '2018-19']\n",
      "2016-17\n",
      "2015-16\n",
      "2014-15\n",
      "2019-20\n",
      "2018-19\n",
      "Saving data to data/2009-10.json\n",
      "Saving data to data/2010-11.json\n",
      "Saving data to data/2011-12.json\n",
      "Saving data to data/2012-13.json\n",
      "Saving data to data/2013-14.json\n",
      "Saving data to data/2014-15.json\n",
      "Saving data to data/2015-16.json\n",
      "Saving data to data/2016-17.json\n",
      "Saving data to data/2017-18.json\n",
      "Saving data to data/2018-19.json\n",
      "Saving data to data/2019-20.json\n"
     ]
    }
   ],
   "source": [
    "players_data = {}\n",
    "for year in range(START_YEAR, END_YEAR + 1):\n",
    "    players_data[str(year)] = {}\n",
    "\n",
    "# loop through first 10 urls\n",
    "for url in urls[:10]:\n",
    "    # get the player's HTML page\n",
    "    soup_file = get_player_soup(url)\n",
    "\n",
    "    seasons = get_player_seasons(soup_file)\n",
    "    print(seasons)\n",
    "\n",
    "    for season_str in seasons:\n",
    "        # Scrape HTML\n",
    "        player = {}\n",
    "        player[URL] = url\n",
    "        \n",
    "        year = int(season_str.split('-')[0]) + 1\n",
    "        if year >= START_YEAR and year <= END_YEAR:\n",
    "            player[SEASON] = season_str\n",
    "            \n",
    "            for key, function in scrap_functions.items():\n",
    "                player[key] = function(soup_file, season=season_str)\n",
    "\n",
    "            players_data[str(year)][url] = player\n",
    "\n",
    "\n",
    "# save each season to a different JSON file\n",
    "for year in range(START_YEAR, END_YEAR + 1):\n",
    "    destination = OUTPUT_DIR / f'{year-1}-{str(year)[2:]}.json'\n",
    "    with open(str(destination), 'w') as f:\n",
    "        print(f'Saving data to {destination}')\n",
    "        json.dump(players_data[str(year)], f, indent=4, default=str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
